# -*- coding: utf-8 -*-
"""SuperResolutionGANhybrid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N5YSLy0aj5QT44MBL7PcfDuJWLCS7Kd4
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os, time

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')
save_dir = '/content/drive/MyDrive/SR_Models'
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

from tensorflow.keras.layers import (Input, Conv2D, Conv2DTranspose, Dense, GlobalAveragePooling2D,
                                     Reshape, Add, Concatenate, Lambda, UpSampling2D,
                                     LeakyReLU, Activation, Multiply)
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input

# =============================================================================
# 1. Data Loading & Preprocessing
# =============================================================================
(x_train, _), (x_test, _) = tf.keras.datasets.cifar10.load_data()
x_train = x_train.astype('float32')/255.0
x_test  = x_test.astype('float32')/255.0

def degrade_images(imgs, size=(16,16)):
    return tf.image.resize(imgs, size, method='area')

x_train_lr = degrade_images(x_train)
x_test_lr  = degrade_images(x_test)

print("Train HR:", x_train.shape, "Train LR:", x_train_lr.shape)
print("Test HR :", x_test.shape,  "Test LR :", x_test_lr.shape)

# =============================================================================
# 2. Advanced Generator Components
# =============================================================================
def multi_scale_block(x, filters=64):
    conv3 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(x)
    conv5 = Conv2D(filters, kernel_size=5, padding='same', activation='relu')(x)
    conv7 = Conv2D(filters, kernel_size=7, padding='same', activation='relu')(x)
    concatenated = Concatenate()([conv3, conv5, conv7])
    fused = Conv2D(filters, kernel_size=1, padding='same', activation='relu')(concatenated)
    return fused

def residual_dense_block(x, filters=64, growth_channels=32, num_layers=4, scaling=0.2):
    concat_features = [x]
    for _ in range(num_layers):
        out = Conv2D(growth_channels, kernel_size=3, padding='same', activation='relu')(
            Concatenate()(concat_features)
        )
        concat_features.append(out)
    merged = Concatenate()(concat_features)
    fused = Conv2D(filters, kernel_size=1, padding='same')(merged)
    fused = Lambda(lambda t: t * scaling)(fused)
    return Add()([x, fused])

def RRDB(x, filters=64, growth_channels=32, num_layers=4, scaling=0.2):
    input_x = x
    for _ in range(3):
        x = residual_dense_block(x, filters, growth_channels, num_layers, scaling)
    x = Lambda(lambda t: t * scaling)(x)
    return Add()([input_x, x])

def self_attention_block(x):
    channels = x.shape[-1]
    f = Conv2D(channels // 8, 1, padding='same')(x)
    g = Conv2D(channels // 8, 1, padding='same')(x)
    h = Conv2D(channels, 1, padding='same')(x)
    f_flat = Reshape((-1, channels // 8))(f)
    g_flat = Reshape((-1, channels // 8))(g)
    h_flat = Reshape((-1, channels))(h)
    s = Lambda(lambda t: tf.matmul(t[0], t[1], transpose_b=True))([f_flat, g_flat])
    beta = Activation('softmax')(s)
    o = Lambda(lambda t: tf.matmul(t[0], t[1]))([beta, h_flat])
    o = Reshape(tf.keras.backend.int_shape(x)[1:])(o)
    o = Conv2D(channels, 1, padding='same')(o)
    return Add()([x, o])

def channel_attention_block(x, reduction=16):
    channels = x.shape[-1]
    avg_pool = GlobalAveragePooling2D()(x)
    dense1 = Dense(channels // reduction, activation='relu')(avg_pool)
    dense2 = Dense(channels, activation='sigmoid')(dense1)
    scale = Reshape((1,1,channels))(dense2)
    return Multiply()([x, scale])

# =============================================================================
# 3. Heavy Generator Model
# =============================================================================
def build_heavy_generator(input_shape=(16,16,3), num_rrdb=8):
    inputs = Input(shape=input_shape)

    # Increase initial channels to 128 for higher capacity
    x = Conv2D(128, 3, padding='same', activation='relu')(inputs)
    x = multi_scale_block(x, filters=128)
    skip = x

    # Use more RRDB blocks (e.g., 8) with increased channels
    for _ in range(num_rrdb):
        x = RRDB(x, filters=128, growth_channels=64, num_layers=4, scaling=0.2)
    x = Add()([skip, x])

    # Global feature extraction branch:
    global_feat = GlobalAveragePooling2D()(x)
    global_feat = Dense(128, activation='relu')(global_feat)
    # Compute the total number of features in x (excluding batch dim)
    feat_shape = tf.keras.backend.int_shape(x)[1:]
    num_feat = np.prod(feat_shape)
    global_feat = Dense(num_feat, activation='relu')(global_feat)
    global_feat = Reshape(feat_shape)(global_feat)

    # Fuse global features with local features
    x = Concatenate()([x, global_feat])
    x = Conv2D(128, 3, padding='same', activation='relu')(x)

    # Additional processing with attention blocks
    x = self_attention_block(x)
    x = channel_attention_block(x, reduction=16)

    # Progressive upsampling: since input is 16x16 and output 32x32, we need one factor of 2
    # Use bilinear upsampling followed by a convolution for refinement.
    x = UpSampling2D(size=(2,2), interpolation='bilinear')(x)
    x = Conv2D(128, 3, padding='same', activation='relu')(x)

    # Further convolutional layers for refinement
    x = Conv2D(128, 3, padding='same', activation='relu')(x)
    outputs = Conv2D(3, 3, padding='same', activation='sigmoid')(x)

    return Model(inputs, outputs, name="Heavy_Generator")

# =============================================================================
# 4. Discriminator (Deep PatchGAN-style; unchanged)
# =============================================================================
def build_discriminator(input_shape=(32,32,3)):
    inputs = Input(shape=input_shape)
    x = Conv2D(64, 3, strides=1, padding='same')(inputs)
    x = LeakyReLU(alpha=0.2)(x)
    filters = 64
    for i in range(4):
        x = Conv2D(filters, 3, strides=2, padding='same')(x)
        x = LeakyReLU(alpha=0.2)(x)
        filters *= 2
    x = Conv2D(1, 3, padding='same')(x)
    return Model(inputs, x, name="Discriminator")

# =============================================================================
# 5. Perceptual Loss Setup Using VGG19
# =============================================================================
vgg = VGG19(weights='imagenet', include_top=False, input_shape=(32,32,3))
perceptual_layer = vgg.get_layer('block3_conv3').output
vgg_model = Model(vgg.input, perceptual_layer)
vgg_model.trainable = False

def perceptual_loss(y_true, y_pred):
    y_true_255 = y_true * 255.0
    y_pred_255 = y_pred * 255.0
    y_true_pre = preprocess_input(y_true_255)
    y_pred_pre = preprocess_input(y_pred_255)
    true_features = vgg_model(y_true_pre)
    pred_features = vgg_model(y_pred_pre)
    return tf.reduce_mean(tf.square(true_features - pred_features))

# =============================================================================
# 6. Instantiate Models & Optimizers
# =============================================================================
generator = build_heavy_generator(num_rrdb=8)
discriminator = build_discriminator()

# Print model summaries
print("Heavy Generator Summary:")
generator.summary()
print("\nDiscriminator Summary:")
discriminator.summary()

g_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9)
d_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9)

mse_loss = tf.keras.losses.MeanSquaredError()
bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)

# =============================================================================
# 7. tf.data Datasets (CIFAR-10)
# =============================================================================
BATCH_SIZE = 64
EPOCHS = 10

train_ds = tf.data.Dataset.from_tensor_slices((x_train_lr, x_train))
train_ds = train_ds.shuffle(10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

val_ds = tf.data.Dataset.from_tensor_slices((x_test_lr, x_test))
val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# =============================================================================
# 8. Custom Training Loop
# =============================================================================
@tf.function
def train_step(lr_imgs, hr_imgs):
    with tf.GradientTape() as d_tape:
        sr_imgs = generator(lr_imgs, training=True)
        d_real = discriminator(hr_imgs, training=True)
        d_fake = discriminator(sr_imgs, training=True)
        d_loss_real = bce_loss(tf.ones_like(d_real), d_real)
        d_loss_fake = bce_loss(tf.zeros_like(d_fake), d_fake)
        d_loss = 0.5 * (d_loss_real + d_loss_fake)
    d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)
    d_optimizer.apply_gradients(zip(d_grads, discriminator.trainable_variables))

    with tf.GradientTape() as g_tape:
        sr_imgs = generator(lr_imgs, training=True)
        d_fake = discriminator(sr_imgs, training=True)
        pixel = mse_loss(hr_imgs, sr_imgs)
        adv = bce_loss(tf.ones_like(d_fake), d_fake)
        perc = perceptual_loss(hr_imgs, sr_imgs)
        g_loss = pixel + 0.01 * adv + 0.1 * perc
    g_grads = g_tape.gradient(g_loss, generator.trainable_variables)
    g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))

    return d_loss, g_loss, pixel, adv, perc

for epoch in range(1, EPOCHS+1):
    start_time = time.time()
    d_losses, g_losses, pix_losses, adv_losses, perc_losses = [], [], [], [], []

    for lr_imgs, hr_imgs in train_ds:
        d_loss, g_loss, pix_loss, adv_loss, perc_loss = train_step(lr_imgs, hr_imgs)
        d_losses.append(d_loss.numpy())
        g_losses.append(g_loss.numpy())
        pix_losses.append(pix_loss.numpy())
        adv_losses.append(adv_loss.numpy())
        perc_losses.append(perc_loss.numpy())

    elapsed = time.time() - start_time
    print(f"Epoch {epoch}/{EPOCHS} - Time: {elapsed:.2f}s")
    print(f"  D_loss: {np.mean(d_losses):.4f} | G_loss: {np.mean(g_losses):.4f} | "
          f"Pixel: {np.mean(pix_losses):.4f} | Adv: {np.mean(adv_losses):.4f} | "
          f"Perc: {np.mean(perc_losses):.4f}")

# =============================================================================
# 9. Validation & Visualization
# =============================================================================
lr_batch, hr_batch = next(iter(val_ds))
sr_batch = generator(lr_batch[:5], training=False).numpy()

fig, axes = plt.subplots(3, 5, figsize=(15,6))
for i in range(5):
    lr_up = tf.image.resize(lr_batch[i:i+1], (32,32), method='nearest')[0]
    axes[0, i].imshow(lr_up)
    axes[0, i].set_title("LR Input")
    axes[0, i].axis('off')

    axes[1, i].imshow(hr_batch[i])
    axes[1, i].set_title("Ground Truth")
    axes[1, i].axis('off')

    axes[2, i].imshow(sr_batch[i])
    axes[2, i].set_title("SR Output")
    axes[2, i].axis('off')
plt.tight_layout()
plt.show()

# =============================================================================
# 10. Save Models in Native Keras Format to Google Drive
# =============================================================================
generator_save_path = os.path.join(save_dir, "Heavy_SR_Generator.keras")
discriminator_save_path = os.path.join(save_dir, "Heavy_SR_Discriminator.keras")
generator.save(generator_save_path)
discriminator.save(discriminator_save_path)
print("Generator saved as:", generator_save_path)
print("Discriminator saved as:", discriminator_save_path)

import matplotlib.pyplot as plt
import numpy as np

# Epoch numbers
epochs = np.arange(1, 11)

# Recorded loss values from training
d_loss     = [0.4015, 0.0550, 0.0470, 0.0195, 0.0157, 0.0096, 0.0077, 0.0069, 0.0046, 0.0048]
g_loss     = [5398.1323, 2047.1825, 1803.3738, 1656.1580, 1584.4299, 1533.7273, 1495.0723, 1460.7246, 1429.2798, 1403.6918]
pixel_loss = [0.0119, 0.0033, 0.0032, 0.0030, 0.0029, 0.0028, 0.0028, 0.0027, 0.0027, 0.0027]
adv_loss   = [2.0351, 5.7519, 6.5621, 8.4850, 9.4731, 10.6208, 11.7328, 12.4801, 13.4597, 14.2348]
perc_loss  = [53980.9961, 20471.2168, 18033.0508, 16560.7012, 15843.3223, 15336.1846, 14949.5215, 14605.9707, 14291.4248, 14035.4678]

# Plot all metrics in a single graph using a logarithmic scale for clarity
plt.figure(figsize=(12,8))
plt.semilogy(epochs, d_loss,     'r-o', label='Discriminator Loss')
plt.semilogy(epochs, g_loss,     'b-o', label='Generator Loss')
plt.semilogy(epochs, pixel_loss, 'g-o', label='Pixel Loss')
plt.semilogy(epochs, adv_loss,   'm-o', label='Adversarial Loss')
plt.semilogy(epochs, perc_loss,  'c-o', label='Perceptual Loss')

plt.xlabel('Epoch')
plt.ylabel('Loss (log scale)')
plt.title('Hybrid Approach Training Loss Metrics over Epochs')
plt.legend()
plt.grid(True, which="both", linestyle="--")
plt.show()

!pip install tensorflow

import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, losses, metrics
import numpy as np
from tensorflow.keras import backend as K
import os
import matplotlib.pyplot as plt
from PIL import Image

# Function to downsample images
def downsample_image(image):
    """Downsample an image to 16x16 using bicubic interpolation."""
    return tf.image.resize(image, [16, 16], method='bicubic')

# Load and preprocess CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Prepare low-resolution and high-resolution pairs
try:
    lr_train = np.array([downsample_image(img).numpy() for img in x_train])
    hr_train = x_train
    lr_test = np.array([downsample_image(img).numpy() for img in x_test])
    hr_test = x_test
except Exception as e:
    print(f"Error in data preparation: {e}")
    raise

# Take subsets for training and validation
subset_size = 5000
lr_train_subset = lr_train[:subset_size]
hr_train_subset = hr_train[:subset_size]

val_subset_size = 1000
lr_val_subset = lr_test[:val_subset_size]
hr_val_subset = hr_test[:val_subset_size]

# Define the refinement block with spatial attention
def refinement_block(x):
    """Refinement block with channel and spatial attention mechanisms."""
    try:
        # First depth-wise separable Conv2D
        x_dw_conv1 = layers.DepthwiseConv2D(kernel_size=3, padding='same')(x)
        x_dw_conv1 = layers.BatchNormalization()(x_dw_conv1)
        x_dw_conv1 = layers.Activation('relu')(x_dw_conv1)
        x_pw_conv1 = layers.Convolution2D(64, kernel_size=1)(x_dw_conv1)

        # Channel Attention
        ch_atn = layers.Lambda(lambda x: K.mean(x, axis=(1, 2)))(x_pw_conv1)
        ch_atn = layers.Dense(16)(ch_atn)
        ch_atn = layers.Activation('relu')(ch_atn)
        ch_atn = layers.Dense(64)(ch_atn)
        ch_atn = layers.Activation('sigmoid')(ch_atn)
        x_ch_atn = layers.Multiply()([x_pw_conv1, ch_atn])

        # Spatial Attention
        sp_atn = layers.Lambda(lambda x: K.mean(x, axis=3))(x_ch_atn)  # Shape: (batch_size, 16, 16)
        sp_atn = layers.Reshape((16, 16, 1))(sp_atn)  # Shape: (batch_size, 16, 16, 1)
        sp_atn = layers.Convolution2D(1, kernel_size=3, padding='same')(sp_atn)
        sp_atn = layers.Activation('sigmoid')(sp_atn)
        x_sp_atn = layers.Multiply()([x_ch_atn, sp_atn])

        # Second depth-wise separable Conv2D
        x_dw_conv2 = layers.DepthwiseConv2D(kernel_size=3, padding='same')(x_sp_atn)
        x_dw_conv2 = layers.BatchNormalization()(x_dw_conv2)
        x_dw_conv2 = layers.Activation('relu')(x_dw_conv2)
        x_pw_conv2 = layers.Convolution2D(64, kernel_size=1)(x_dw_conv2)

        # Residual connection
        x = layers.Add()([x_pw_conv2, x])
        return x
    except Exception as e:
        print(f"Error in refinement block: {e}")
        raise

# Create the generator model
def create_generator():
    """Create the generator model with refinement blocks and upsampling."""
    try:
        inp = layers.Input(shape=(16, 16, 3))
        x = layers.Convolution2D(64, kernel_size=3, padding='same', activation='relu')(inp)

        # Apply refinement blocks
        for _ in range(5):
            x = refinement_block(x)

        # Global feature integration
        global_feat = layers.Lambda(lambda x: K.mean(x, axis=(1, 2)))(x)
        global_feat = layers.Dense(32)(global_feat)
        global_feat = layers.Activation('relu')(global_feat)
        global_feat = layers.Dense(64)(global_feat)
        global_feat = layers.Activation('relu')(global_feat)
        global_feat = layers.Reshape((1, 1, 64))(global_feat)
        x = layers.Multiply()([x, global_feat])

        # Upsampling with pixel shuffle
        x = layers.Convolution2D(256, kernel_size=1)(x)
        x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)
        out = layers.Convolution2D(3, kernel_size=3, padding='same', activation='sigmoid')(x)

        return models.Model(inp, out)
    except Exception as e:
        print(f"Error in creating generator: {e}")
        raise

# Check for TPU and set up strategy
try:
    if 'COLAB_TPU_ADDR' in os.environ:
        tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
        print('TPU address is', tpu_address)

        # Initialize TPU
        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)
        tf.config.experimental_connect_to_cluster(resolver)
        tf.tpu.experimental.initialize_tpu_system(resolver)

        # Create a TPUStrategy
        strategy = tf.distribute.TPUStrategy(resolver)

        # Define the model within the strategy scope
        with strategy.scope():
            generator = create_generator()
            generator.compile(optimizer=optimizers.Adam(learning_rate=0.001),
                              loss='mean_absolute_error',
                              metrics=['accuracy'])
    else:
        generator = create_generator()
        generator.compile(optimizer=optimizers.Adam(learning_rate=0.001),
                          loss='mean_absolute_error',
                          metrics=['accuracy'])
except Exception as e:
    print(f"Error in TPU setup or model compilation: {e}")
    raise

# Print model summary
try:
    generator.summary()
except Exception as e:
    print(f"Error in printing model summary: {e}")
    raise

# Train the model for 100 epochs
try:
    history = generator.fit(lr_train_subset, hr_train_subset, epochs=100, batch_size=32,
                            validation_data=(lr_val_subset, hr_val_subset),
                            verbose=1)  # verbose=1 shows progress percentage
except Exception as e:
    print(f"Error in training: {e}")
    raise

# Plot loss curves
try:
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()
except Exception as e:
    print(f"Error in plotting loss curves: {e}")
    raise

# Function to display sample outputs
def plot_results(model):
    """Display low-resolution, super-resolved, and high-resolution images."""
    try:
        idx = np.random.randint(0, len(lr_test))
        lr_img = lr_test[idx]  # Shape: (16, 16, 3)
        hr_img = hr_test[idx]  # Shape: (32, 32, 3)
        sr_img = model.predict(np.expand_dims(lr_img, axis=0))[0]  # Shape: (32, 32, 3)

        # Convert NumPy arrays to PIL images
        lr_img_pil = Image.fromarray((lr_img * 255).astype('uint8'))  # Convert LR to PIL
        lr_img_pil = lr_img_pil.resize((32, 32), Image.BICUBIC)  # Resize from 16x16 to 32x32

        hr_img_pil = Image.fromarray((hr_img * 255).astype('uint8'))  # HR is already 32x32

        sr_img_pil = Image.fromarray((sr_img * 255).astype('uint8'))  # SR is already 32x32

        # Plot images
        fig = plt.figure(figsize=(15, 5))

        ax1 = fig.add_subplot(131)
        ax1.set_title('Low Resolution (resized)')
        ax1.axis('off')
        ax1.imshow(lr_img_pil)

        ax2 = fig.add_subplot(132)
        ax2.set_title('Super Resolved')
        ax2.axis('off')
        ax2.imshow(sr_img_pil)

        ax3 = fig.add_subplot(133)
        ax3.set_title('High Resolution')
        ax3.axis('off')
        ax3.imshow(hr_img_pil)

        plt.show()
    except Exception as e:
        print(f"Error in plotting results: {e}")
        raise

# Display sample outputs
try:
    plot_results(generator)
except Exception as e:
    print(f"Error in displaying sample outputs: {e}")
    raise

import matplotlib.pyplot as plt

# Data (Loss values for each epoch)
epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
d_loss = [0.4015, 0.0550, 0.0470, 0.0195, 0.0157, 0.0096, 0.0077, 0.0069, 0.0046, 0.0048]
g_loss = [5398.1323, 2047.1825, 1803.3738, 1656.1580, 1584.4299, 1533.7273, 1495.0723, 1460.7246, 1429.2798, 1403.6918]
pixel_loss = [0.0119, 0.0033, 0.0032, 0.0030, 0.0029, 0.0028, 0.0028, 0.0027, 0.0027, 0.0027]
adv_loss = [2.0351, 5.7519, 6.5621, 8.4850, 9.4731, 10.6208, 11.7328, 12.4801, 13.4597, 14.2348]
perc_loss = [53980.9961, 20471.2168, 18033.0508, 16560.7012, 15843.3223, 15336.1846, 14949.5215, 14605.9707, 14291.4248, 14035.4678]

# Create a figure and a set of subplots with two y-axes
fig, ax1 = plt.subplots(figsize=(12, 6))

# Plot D_loss, Pixel Loss, Adv Loss, and Perc Loss on the first y-axis
ax1.plot(epochs, d_loss, label='D_loss', color='red', marker='o')
ax1.plot(epochs, pixel_loss, label='Pixel Loss', color='green', marker='o')
ax1.plot(epochs, adv_loss, label='Adv Loss', color='purple', marker='o')
ax1.plot(epochs, perc_loss, label='Perc Loss', color='orange', marker='o')

# Set the labels and title for the first axis
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Loss (Smaller Values)')
ax1.set_title('Losses During Training Over Epochs')
ax1.grid(True)

# Create a second y-axis to plot G_loss
ax2 = ax1.twinx()  # Instantiate the second y-axis
ax2.plot(epochs, g_loss, label='G_loss', color='blue', marker='o')

# Set the label for the second axis
ax2.set_ylabel('G_loss (Larger Values)')

# Adding legends for both y-axes
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')

# Adjust layout for better spacing
plt.tight_layout()

# Show plot
plt.show()

